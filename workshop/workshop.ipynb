{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapotte moffen met een classificatiemodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inhoud:**\n",
    "1. [Installeer packages and laad de data](#1)\n",
    "1. [Data Exploratie](#2)\n",
    "1. [Preparee de data](#3)\n",
    "1. [Analyse ](#4)\n",
    "1. [Splits train- en testset](#5)\n",
    "1. [Train en valideer de modellen](#6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> \n",
    "\n",
    "\n",
    "## 1. Installeer packages en laad de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Installeer packages\n",
    "import pandas as pd       # 'as' := we korten het package af voor veel gebruik\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.tree import DecisionTreeClassifier         # Modeling CART Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier     # Modeling Random Forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # Modeling XGBoost\n",
    "from sklearn import metrics                             # Performance statistieken\n",
    "from sklearn.model_selection import train_test_split    # Split train-/testset\n",
    "from sklearn.metrics import classification_report       # Performance rapport van classificatie model\n",
    "from sklearn.metrics import f1_score,average_precision_score                    # f1 score of model\n",
    "from six import StringIO                                # Nodig voor grafiek Decision Tree\n",
    "from sklearn.tree import export_graphviz                # Nodig voor grafiek Decision Tree\n",
    "import pydotplus                                        # Nodig voor grafiek Decision Tree\n",
    "from IPython.display import Image                       # Nodig voor grafiek Decision Tree\n",
    "from sklearn.tree import export_graphviz                # Nodig voor grafiek Decision Tree\n",
    "import graphviz as gv                                   # Nodig voor grafiek Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Laad de data\n",
    "\n",
    "inputdata = pd.read_csv(\"Gefaalde_Moffen.csv\")\n",
    "\n",
    "#    Krijg een overzicht van de data\n",
    "inputdata.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> \n",
    "\n",
    "\n",
    "## 2. Data Exploratie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Haal een overzicht op van de data\n",
    "#    Haal de hoeveelheid rijen en kolommen op\n",
    "print('(nrow, ncol):', inputdata.shape)     \n",
    "\n",
    "#    Laat een korte samenvatting van de numerieke variabelen zien\n",
    "inputdata.describe()                        # min/max, count, mean, std and percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Check het data type van iedere variabele\n",
    "print(pd.DataFrame(inputdata.dtypes, columns=['Datatype']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Krijg een overzicht van de NULLS in de dataset\n",
    "nulls = pd.DataFrame(inputdata.isnull().sum(), columns=['# NULLS'])        # Hoeveelheid NULLS \n",
    "\n",
    "lst={}                                                                     # Hoeveelheid NULLS als percentage\n",
    "for col in inputdata.columns:                                       \n",
    "    lst[col]=np.sum(inputdata.loc[:,col].isnull())/len(inputdata.loc[:,col])\n",
    "percNulls = pd.DataFrame(pd.Series(lst), columns=['% NULLS'])\n",
    "\n",
    "print(pd.concat([nulls, percNulls], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyseer de te voorspellen variabele\n",
    "target = '???'\n",
    "\n",
    "inputdata[target].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyseer dummies\n",
    "df_defect = inputdata[inputdata['??']==??]\n",
    "df_defect.groupby('??').count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f) Analyseer de distributie van continue variabelen\n",
    "variable_analyzed = '??'\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.hist((inputdata[variable_analyzed]), bins=250, color = 'blue', edgecolor = 'blue')\n",
    "plt.title('Distributie van {}'.format(variable_analyzed))\n",
    "plt.xlabel(variable_analyzed)\n",
    "plt.ylabel('#')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_analyzed = '??'\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.hist((inputdata[variable_analyzed]), bins=250, color = 'blue', edgecolor = 'blue')\n",
    "plt.title('Distributie van {}'.format(variable_analyzed))\n",
    "plt.xlabel(variable_analyzed)\n",
    "plt.ylabel('#')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> \n",
    "\n",
    "\n",
    "## 3. Prepareer de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Verwijder de uitschieters (waar variabelen een onmogelijk hoge waarde hebben)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Verwerk missende waardes\n",
    "\n",
    "inputdata = inputdata.fillna(inputdata.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c ) Maak een dummy van de te voorspellen variabele\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> \n",
    "\n",
    "\n",
    "## 4. Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdata.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Maak een staafdiagram om de relatie tussen de dummies en de te voorspellen variabele te onderzoeken, bekijk \n",
    "# specifieke variabelen om het aantal tabbelen overzichtelijk te houden\n",
    "\n",
    "dummies = ['???'\n",
    "          ]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,140))\n",
    "for i, column in enumerate(dummies):\n",
    "    plt.subplot(math.ceil(len(dummies)/2), 2, i+1)\n",
    "    sns.barplot(inputdata[column], inputdata[target], palette='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  b) Laat een correlatie matrix zien om correlaties tussen alle variabelen te onderzoeken, bekijk\n",
    "# specifieke variabelen om de matrix overzichtelijk te houden\n",
    "\n",
    "columns = ['???'\n",
    "          ]\n",
    "\n",
    "correlation = inputdata[columns]\n",
    "corrmat = correlation.corr().round(2)\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True, annot=True, cmap='RdBu_r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> \n",
    "\n",
    "\n",
    "## 5. Splits train- en testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a> \n",
    "\n",
    "\n",
    "## 6. Train en valideer modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6a\"></a> \n",
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laat de namen van alle variabelen zien\n",
    "data_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definieer X en y \n",
    "X_variables = ['???']\n",
    "y_variable = '???'\n",
    "\n",
    "X_train = data_train.loc[:, X_variables]\n",
    "y_train = data_train[y_variable]\n",
    "X_test = data_test.loc[:, X_variables]\n",
    "y_test = data_test[y_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Kies de model parameters \n",
    "#    Note: als Min_bucket te groot is, kan de tree mogelijk niet splitsen, als het te klein is wordt de tree misschien te \n",
    "#    groot om te interpreteren\n",
    "Min_num_splits = ??                            # Minimum hoeveelheid van items te splitten\n",
    "Min_bucket     = ??                            # Minimum hoeveelheid van items per bucket\n",
    "Max_depth      = ??                            # Maximum depth of final tree (nr of levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Estimate het model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Maak voorspellingen voor de test set\n",
    "\n",
    "\n",
    "\n",
    "#    Laat de eerste 5 rijen van de voorspelling probabilities en de overeenkomende voorspelling zien\n",
    "pd.concat([pd.DataFrame(preds_proba, columns=[\"Prob. 0\", \"Prob. 1\"]), pd.DataFrame(preds, columns=[\"Prediction\"])], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Bereken het optimale cut-off punt\n",
    "cost_TP = ??\n",
    "cost_TN = ??\n",
    "cost_FP = ??\n",
    "cost_FN = ??\n",
    "total_cost = math.inf\n",
    "\n",
    "for i in np.linspace(0,1,100,endpoint=False):\n",
    "    y_pred = (preds_proba[:,1]>i).astype('int')\n",
    "    results = metrics.confusion_matrix(y_pred,y_test)\n",
    "    TN = results[0][0]\n",
    "    FN = results[0][1]\n",
    "    FP = results[1][0]\n",
    "    TP = results[1][1]\n",
    "    \n",
    "    # Bereken cutoff-punt\n",
    "    cost = TN*cost_TN + TP*cost_TP + FP*cost_FP + FN*cost_FN\n",
    "    total_cost = min(total_cost,cost)\n",
    "    if(total_cost == cost):\n",
    "        opt_cutoff = i\n",
    "        \n",
    "print('Optimale cut-off:', opt_cutoff)\n",
    "\n",
    "#    Maak voorspellingen voor de test set met het optimale cut-off punt\n",
    "preds = (preds_proba[:,1] > opt_cutoff).astype('int')\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    bepaal wat de 200 moffen zijn met de grootste kans om te falen\n",
    "chanceOfFailure = preds_proba[:,1]\n",
    "\n",
    "moffenPerJaar = 200\n",
    "cutOffChance = np.sort(chanceOfFailure)[::-1][moffenPerJaar]\n",
    "\n",
    "predictions = ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Plot tpr vs 1-fpr\n",
    "fpr, tpr, t = metrics.roc_curve(y_test, preds_proba[:,1])\n",
    "i = np.arange(len(tpr)) # index for df\n",
    "roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i)\n",
    "                    ,'1-fpr' : pd.Series(1-fpr, index = i)\n",
    "                    ,'tf' : pd.Series(tpr - (1-fpr), index = i)\n",
    "                    ,'thresholds' : pd.Series(t, index = i)})\n",
    "print(roc.loc[(roc.tf-0).abs().argsort()[:1]])\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(roc['tpr'])\n",
    "plt.plot(roc['1-fpr'], color = 'red')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('1-False Positive Rate')\n",
    "ax.set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) Evalueer resultaten\n",
    "#    i. Maak een confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    ii. Maak een classificatie rapport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    iii. Verkrijg de feature importances van de tree\n",
    "importances = mytree.feature_importances_ \n",
    "std = np.std([mytree.feature_importances_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "importances_features = []\n",
    "print(\"Feature ranking:\")                    # Print the feature ranking\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"Feature %d (%s) %f\" % (indices[f], X_variables[indices[f]], importances[indices[f]]))\n",
    "    importances_features.append(X_variables[indices[f]])\n",
    "\n",
    "plt.figure(figsize=(7.5,5))\n",
    "plt.figure()                                 # Plot the feature importances \n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.title(\"Feature importances\")\n",
    "plt.ylabel(\"Importance in terms of decreasing the weighted impurity\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.xticks(range(X_train.shape[1]), importances_features, rotation = 30)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    iv. Maak de ROC curve\n",
    "fpr, tpr, t = metrics.roc_curve(y_test, preds_proba[:,1])\n",
    "\n",
    "#     v. Bereken AUC\n",
    "CART_roc_auc_tree = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')      # Plot results\n",
    "plt.plot(fpr, tpr, lw=2, alpha=0.3, label='Mean ROC Decision Tree CART (AUC = %0.2f)' % (CART_roc_auc_tree))\n",
    "plt.title('ROC curve')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e) Visualizeer de Decision Tree\n",
    "dot_data = StringIO()\n",
    "export_graphviz(mytree, out_file=dot_data,           # mytree := name of your decision treee\n",
    "                filled=True, rounded=True,\n",
    "                feature_names=X_variables,\n",
    "                special_characters=True)\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6b\"></a> \n",
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definieer de train en test set\n",
    "\n",
    "X_train = data_train.loc[:, X_variables]\n",
    "y_train = data_train[y_variable]\n",
    "X_test = data_test.loc[:, X_variables]\n",
    "y_test = data_test[y_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Kies de model parameters \n",
    "#     Note: Je kan de grootte van je forest aanpassen met N_trees, maar let er op dat de berekeningsduur dan toeneemt\n",
    "#     Note: Als Min_bucket te groot is, splitsen de trees misschien niet\n",
    "N_trees        = ??                           # Hoeveelheid estimated trees\n",
    "Min_num_splits = ??                            # Minimum hoeveelheid van te splitten items    \n",
    "Min_bucket     = ??  # Minimum hoeveelheid van items per bucket\n",
    "Max_depth      = ??                            # Maximum depth van iedere tree (hoeveelheid levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Estimate het model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Maak voorspellingen voor de test set\n",
    "\n",
    "\n",
    "\n",
    "#    Laat de eerste 5 rijen van de voorspelling probabilities en de overeenkomende voorspelling zien\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    bepaal wat de 200 moffen zijn met de grootste kans om te falen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) Evaluaeer resultaten\n",
    "#    i. Maak een confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    ii. Maak een classificatie rapport\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    iii. Verkrijg de feature importances van de tree\n",
    "importances = forest.feature_importances_ \n",
    "std = np.std([forest.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "importances_features = []\n",
    "print(\"Feature ranking:\")                    # Print the feature ranking\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"Feature %d (%s) %f\" % (indices[f], X_variables[indices[f]], importances[indices[f]]))\n",
    "    importances_features.append(X_variables[indices[f]])\n",
    "\n",
    "plt.figure(figsize=(7.5,5))\n",
    "plt.figure()                                 # Plot the feature importances \n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.title(\"Feature importances\")\n",
    "plt.ylabel(\"Importance in terms of decreasing the weighted impurity\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.xticks(range(X_train.shape[1]), importances_features, rotation = 30)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    iv. Maak de ROC curve\n",
    "\n",
    "\n",
    "#     v. Bereken de AUC\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')      # Plot results\n",
    "plt.plot(fpr, tpr, lw=2, alpha=0.3, label='Mean ROC Decision Tree RF (AUC = %0.2f)' % (RF_roc_auc_tree))\n",
    "plt.title('ROC curve')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6v\"></a> \n",
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definieer X and y \n",
    "X_variables = ['???'             # ADJUST VARIABLES TO THOSE YOU WISH TO INCLUDE\n",
    "                ]\n",
    "y_variable = '??'\n",
    "\n",
    "X_train = data_train.loc[:, X_variables]\n",
    "y_train = data_train[y_variable]\n",
    "X_test = data_test.loc[:, X_variables]\n",
    "y_test = data_test[y_variable]\n",
    "\n",
    "print(X_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Kies de model parameters \n",
    "N_trees        = ??                         # Hoeveelheid estimated trees\n",
    "Max_depth      = ??                             # Maximum depth van iedere tree (hoeveelheid levels)\n",
    "Learning_rate  = ??                             # The learning rate ('eta')\n",
    "Min_bucket     = ??                           # Minimum hoeveelheid van items per bucket\n",
    "Subsample      = ??                          # Subsample ratio van de training instance\n",
    "Verbose        = ??                             # Of er tijdens het boosten berichten geprint moeten worden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Estimate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Maak voorspellingen voor de test set\n",
    "\n",
    "#    Laat de eerste 5 rijen van de voorspelling probabilities en de overeenkomende voorspelling zien\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    bepaal wat de 200 moffen zijn met de grootste kans om te falen\n",
    "chanceOfFailure = preds_proba[:,1]\n",
    "\n",
    "moffenPerJaar = 200\n",
    "cutOffChance = np.sort(chanceOfFailure)[::-1][moffenPerJaar]\n",
    "\n",
    "predictions = np.array([True if chance > cutOffChance else False for chance in chanceOfFailure])\n",
    "\n",
    "index_values = np.where(predictions == True)\n",
    "print(index_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) Evalueer de resultaten\n",
    "#    i. Maak een confusion matrix\n",
    "print(pd.crosstab(preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    ii. Maak een classificatie rapport\n",
    "print(classification_report(y_test, preds))\n",
    "f1_XGB = f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    iii. Krijg de feature importances van het XGBoost model\n",
    "importances = XGB.feature_importances_ \n",
    "std = np.std([XGB.feature_importances_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "importances_features = []\n",
    "print(\"Feature ranking:\")                    # Print the feature ranking\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"Feature %d (%s) %f\" % (indices[f], X_variables[indices[f]], importances[indices[f]]))\n",
    "    importances_features.append(X_variables[indices[f]])\n",
    "\n",
    "if False:\n",
    "    plt.figure(figsize=(7.5,5))\n",
    "    plt.figure()                                 # Plot the feature importances \n",
    "    plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.ylabel(\"Importance in terms of decreasing the weighted impurity\")\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.xticks(range(X_train.shape[1]), importances_features, rotation = 30)\n",
    "    plt.xlim([-1, X_train.shape[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak de ROC curve\n",
    "\n",
    "\n",
    "# Bereken AUC\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')      # Plot results\n",
    "plt.plot(fpr, tpr, lw=2, alpha=0.3, label='Mean ROC Decision Tree XGBoost (AUC = %0.2f)' % (XGB_roc_auc_tree))\n",
    "plt.title('ROC curve')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vergelijk de modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
